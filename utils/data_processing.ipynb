{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basins in Juniata RB: 0      cat-88306\n",
      "1      cat-87647\n",
      "2      cat-88001\n",
      "3      cat-88268\n",
      "4      cat-88269\n",
      "         ...    \n",
      "789    cat-88404\n",
      "790    cat-88405\n",
      "791    cat-88318\n",
      "792    cat-87405\n",
      "793    cat-87639\n",
      "Name: divide_id, Length: 794, dtype: object (unique: 794)\n"
     ]
    }
   ],
   "source": [
    "# Get subset of ids for JRB basins.\n",
    "import geopandas as gpd\n",
    "\n",
    "gdf = gpd.read_file(r\"C:\\Users\\LeoLo\\Desktop\\jrb_2.gpkg\", layer=\"flowpaths\")\n",
    "# Many more layers 'divides', 'lakes', 'nexus', 'pois', 'hydrolocations', 'flowpath-attributes', \n",
    "# 'flowpath-attributes-ml', 'network', 'divide-attributes'\n",
    "\n",
    "# print(gdf.head())\n",
    "print(f\"Basins in Juniata RB: {gdf.divide_id} (unique: {gdf.divide_id.nunique()})\")\n",
    "jrb_divide_ids = list(gdf.divide_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 225MB\n",
      "Dimensions:            (divide_id: 839543)\n",
      "Coordinates:\n",
      "  * divide_id          (divide_id) <U11 37MB 'cat-1068193' ... 'cat-3014411'\n",
      "Data variables: (12/28)\n",
      "    FW                 (divide_id) float64 7MB 0.06157 0.01494 ... 7.854e-07 0.0\n",
      "    HWSD_clay          (divide_id) float64 7MB 14.64 29.69 25.17 ... 28.94 28.95\n",
      "    HWSD_sand          (divide_id) float64 7MB 65.4 22.53 24.07 ... 26.62 26.61\n",
      "    T_clay             (divide_id) float64 7MB 6.226 25.25 13.73 ... 23.0 23.0\n",
      "    uparea             (divide_id) float64 7MB 110.2 10.08 211.7 ... 3.888 4.4\n",
      "    T_gravel           (divide_id) float64 7MB 17.23 4.0 8.132 ... 8.0 8.0 8.0\n",
      "    ...                 ...\n",
      "    ETPOT_Hargr        (divide_id) float64 7MB 819.9 853.7 ... 1.061e+03\n",
      "    meanTa             (divide_id) float64 7MB 3.293 5.532 5.988 ... 6.095 6.084\n",
      "    SoilGrids1km_clay  (divide_id) float64 7MB 14.81 23.31 21.97 ... 24.38 24.38\n",
      "    snow_fraction      (divide_id) float64 7MB 0.2327 0.2647 ... 0.05644 0.05755\n",
      "    aridity            (divide_id) float64 7MB 1.248 1.41 1.475 ... 3.15 3.144\n",
      "    NDVI               (divide_id) float64 7MB 0.4939 0.4492 ... 0.2371 0.2374\n",
      "\n",
      " --------\n",
      "Attribute data has 11319 duplicate divide_id values.\n",
      "\n",
      " --------\n",
      "Forcing data has 11319 duplicate divide_id values. \n",
      " see the proceeding for instance...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FW</th>\n",
       "      <th>HWSD_clay</th>\n",
       "      <th>HWSD_sand</th>\n",
       "      <th>T_clay</th>\n",
       "      <th>uparea</th>\n",
       "      <th>T_gravel</th>\n",
       "      <th>meanelevation</th>\n",
       "      <th>meanP</th>\n",
       "      <th>HWSD_gravel</th>\n",
       "      <th>seasonality_P</th>\n",
       "      <th>...</th>\n",
       "      <th>HWSD_silt</th>\n",
       "      <th>meanslope</th>\n",
       "      <th>permeability</th>\n",
       "      <th>seasonality_PET</th>\n",
       "      <th>ETPOT_Hargr</th>\n",
       "      <th>meanTa</th>\n",
       "      <th>SoilGrids1km_clay</th>\n",
       "      <th>snow_fraction</th>\n",
       "      <th>aridity</th>\n",
       "      <th>NDVI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>divide_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat-100890</th>\n",
       "      <td>0.007916</td>\n",
       "      <td>26.025530</td>\n",
       "      <td>41.448939</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.119245</td>\n",
       "      <td>4.0</td>\n",
       "      <td>869.999678</td>\n",
       "      <td>1362.221376</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.177600</td>\n",
       "      <td>...</td>\n",
       "      <td>32.525531</td>\n",
       "      <td>10.698865</td>\n",
       "      <td>-14.050000</td>\n",
       "      <td>0.650494</td>\n",
       "      <td>828.667336</td>\n",
       "      <td>3.078015</td>\n",
       "      <td>8.687385</td>\n",
       "      <td>0.396185</td>\n",
       "      <td>0.609418</td>\n",
       "      <td>0.635147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat-100890</th>\n",
       "      <td>0.016557</td>\n",
       "      <td>25.646412</td>\n",
       "      <td>42.207175</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.119245</td>\n",
       "      <td>4.0</td>\n",
       "      <td>758.952248</td>\n",
       "      <td>1354.689346</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.147528</td>\n",
       "      <td>...</td>\n",
       "      <td>32.146412</td>\n",
       "      <td>10.058972</td>\n",
       "      <td>-14.049843</td>\n",
       "      <td>0.652170</td>\n",
       "      <td>816.112551</td>\n",
       "      <td>3.319549</td>\n",
       "      <td>9.248475</td>\n",
       "      <td>0.392257</td>\n",
       "      <td>0.608191</td>\n",
       "      <td>0.566833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  FW  HWSD_clay  HWSD_sand  T_clay     uparea  T_gravel  \\\n",
       "divide_id                                                                 \n",
       "cat-100890  0.007916  26.025530  41.448939     4.0  44.119245       4.0   \n",
       "cat-100890  0.016557  25.646412  42.207175     4.0  44.119245       4.0   \n",
       "\n",
       "            meanelevation        meanP  HWSD_gravel  seasonality_P  ...  \\\n",
       "divide_id                                                           ...   \n",
       "cat-100890     869.999678  1362.221376          4.5       0.177600  ...   \n",
       "cat-100890     758.952248  1354.689346          4.5       0.147528  ...   \n",
       "\n",
       "            HWSD_silt  meanslope  permeability  seasonality_PET  ETPOT_Hargr  \\\n",
       "divide_id                                                                      \n",
       "cat-100890  32.525531  10.698865    -14.050000         0.650494   828.667336   \n",
       "cat-100890  32.146412  10.058972    -14.049843         0.652170   816.112551   \n",
       "\n",
       "              meanTa  SoilGrids1km_clay  snow_fraction   aridity      NDVI  \n",
       "divide_id                                                                   \n",
       "cat-100890  3.078015           8.687385       0.396185  0.609418  0.635147  \n",
       "cat-100890  3.319549           9.248475       0.392257  0.608191  0.566833  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load netcdf forcing and attribute files + trim to JRB.\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "attrs_path = r\"C:\\Users\\LeoLo\\Desktop\\attributes.nc\"\n",
    "forc_path = r\"X:\\forcings.nc\" #\"C:\\Users\\LeoLo\\Desktop\\forcings.nc\"\n",
    "\n",
    "# Open the NetCDF and convert to DataFrame\n",
    "d_a = xr.open_dataset(attrs_path)\n",
    "# attrs = d_a.to_dataframe()\n",
    "\n",
    "d_f = xr.open_dataset(forc_path)\n",
    "# forc = d_f.to_dataframe()\n",
    "\n",
    "# Display the dataset\n",
    "print(d_a)\n",
    "\n",
    "\n",
    "# Get the divide_id coordinate\n",
    "divide_ids = d_a['divide_id'].values\n",
    "\n",
    "# Find duplicate divide_id values\n",
    "unique, counts = np.unique(divide_ids, return_counts=True)\n",
    "duplicates = unique[counts > 1]\n",
    "print(f\"\\n --------\\nAttribute data has {len(duplicates)} duplicate divide_id values.\")\n",
    "\n",
    "\n",
    "# Find duplicate divide_id values\n",
    "divide_ids = d_f['divide_id'].values\n",
    "unique, counts = np.unique(divide_ids, return_counts=True)\n",
    "duplicates = unique[counts > 1]\n",
    "print(f\"\\n --------\\nForcing data has {len(duplicates)} duplicate divide_id values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only select the divide_ids that are in the JRB, and select the first occurance of any duplicate divide_ids.\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "## For forcing\n",
    "divide_ids = d_f['divide_id'].values\n",
    "\n",
    "# Find the first occurrence of each divide_id\n",
    "unique_indices = np.unique(divide_ids, return_index=True)[1]\n",
    "first_occurrence_mask = np.zeros_like(divide_ids, dtype=bool)\n",
    "first_occurrence_mask[unique_indices] = True\n",
    "\n",
    "# Apply the mask to the dataset\n",
    "unique_d_f = d_f.isel(divide_id=first_occurrence_mask)\n",
    "\n",
    "# Subset the dataset to include only the desired divide_ids\n",
    "subset_d_f = unique_d_f.sel(divide_id=jrb_divide_ids)\n",
    "\n",
    "\n",
    "## For attributes\n",
    "divide_ids = d_a['divide_id'].values\n",
    "unique_indices = np.unique(divide_ids, return_index=True)[1]\n",
    "first_occurrence_mask = np.zeros_like(divide_ids, dtype=bool)\n",
    "first_occurrence_mask[unique_indices] = True\n",
    "\n",
    "unique_d_a = d_a.isel(divide_id=first_occurrence_mask)\n",
    "subset_d_a = unique_d_a.sel(divide_id=jrb_divide_ids)\n",
    "\n",
    "\n",
    "## Convert to dataframe\n",
    "forc = subset_d_f.to_dataframe()\n",
    "attrs = subset_d_a.to_dataframe()\n",
    "\n",
    "\n",
    "## Trim time to 2000-2005 (divide_id is subindexed by time)\n",
    "# Ensure the second level (time) is a DatetimeIndex\n",
    "forc.index = forc.index.set_levels(pd.to_datetime(forc.index.levels[1]), level=1)\n",
    "start_date = '2000-01-01'\n",
    "end_date = '2005-12-31'\n",
    "forc = forc.loc[(slice(None), slice(start_date, end_date)), :]\n",
    "\n",
    "# Unstack divide_id so that time is the main index\n",
    "forc_unstacked = forc.unstack(level=0)  # Now columns are MultiIndex (divide_id, variable)\n",
    "forc_array = forc_unstacked.to_numpy().reshape(len(forc_unstacked), len(forc_unstacked.columns.levels[0]), -1)\n",
    "\n",
    "forc_array = np.swapaxes(forc_array, 2, 1)\n",
    "\n",
    "f_xr = subset_d_f.to_array()\n",
    "f_xr = np.swapaxes((np.swapaxes(np.swapaxes(f_xr, 1, 0), 2, 1)), 0, 1)\n",
    "\n",
    "f_xr = f_xr[:2192,]\n",
    "\n",
    "\n",
    "## Save to file\n",
    "forc_path = r\"C:\\Users\\LeoLo\\Desktop\\forcings_jrb\"\n",
    "attrs_path = r\"C:\\Users\\LeoLo\\Desktop\\attributes_jrb\"\n",
    "\n",
    "np.save(forc_path, forc_array)  # (2192, 794, 3)\n",
    "np.save(attrs_path, attrs.to_numpy())  # (794, 28)\n",
    "\n",
    "# save the netcdf files\n",
    "subset_d_a.to_netcdf(r\"C:\\Users\\LeoLo\\Desktop\\attributes_jrb.nc\")\n",
    "subset_d_f.to_netcdf(r\"C:\\Users\\LeoLo\\Desktop\\forcings_jrb.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
